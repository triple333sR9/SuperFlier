# SuperFlier
Developer: Jordan Yu @triple333sR9
### Intro
This repository was used to train a model that when given an image of a bird, determines if the bird is flying, defined by whether the wings are expanded or closed.

### Environment
##### Structure: Pytorch
##### Programing language: Python 3.13.9

##### Data set
Curated from images by Jo Wu.

Total of 1445 samples (Fly: 273, NoFly: 1172, see ./data/train) with the bird_labels.csv showing whether the image is labeled as "fly" (label of 1) or "nofly" (label of 0). CSV was generated from the code in preprocess_data.py, which included re-labelling of image names. Test samples are removed from the csv using prepare_samples.py to be used for testing and visualisation purposes after models are trained (see ./data/test). During the training process, the training data is further split into training, validation and testing splits for evaluation purposes.

##### Pretrained Models Used
- Resnet
- Densenet
- EfficientNet
Other models attempted but removed due to poor performance include CNN without backbone, efficientnet, autoencoder and VAE.

##### Hyperparameters selected (see model top0_***.pth)

- EfficientNet_b3
- RMSprop optimizer
- 5e-05 learning rate
- freeze last block
- drop out rate of 0.2
- batch size 32
- medium augmentation (see configuration for details)
- epochs 15
- image size of 384x384 pixels

See CONFIG_TRACK.md for more complete list of hyperparameters tested.

Note that Config.py was used originally to list and generate configurations for grid search, however due to memory issues, the last round of grid search only used the best ten configuration (hence more specific) from the previous round which was more systematic exploration. As such, the configurations for grid search is doubled up at grid_search.py. To run grid search properly, changes are required to consolidate the config parameters.

### Best Performing Model
See /models/grid_search for actual model (.pth file format). See results/grid_search_results.csv for more detailed evaluation comparing each of the models.

##### top0_efficientnet_b3_RMSprop_last_block
| Evaluation Metric | Value              |
|-------------------|--------------------|
| best_val_f1       | 0.9795918367346939 |
| test_accuracy     | 0.9862068965517241 |
| test_precision    | 0.9310344827586207 |
| test_recall       | 1.0                |
| test_specificity  | 0.9830508474576272 |
| test_f1           | 0.9642857142857143 |
| test_auc          | 0.9908976773383553 |
| tp                | 27                 |
| tn                | 116                |
| fp                | 2                  |
| fn                | 0                  |

Confusion matrix used a total of 145 samples for testing purposes (aka tp+tn+fp+fn = 145).

Based on this, an additional model was also ran (see selected_model_results.csv a nd best_***.pth, config specified in main.py to override the variables in config.py), with heavier augmentation,
image size of 640x640 pixels, reduced batch size of 16, increased epochs of 50. This model underperformed the models generated by the grid search despite the extended training time taken and thus was not selected for usage.

A lesson to be learnt here is that bigger is not always better. Heavy augmentation and increased image size dramatically increased training time and memory requirements and yet it did not produce performance what were visibly better than the smaller models. Perhaps in actual practice and use in the real world, there may be unforeseen advantages over the smaller models, but that was beyond the scope of this project. The efficientNet model labeled with the prefix of "top0" was selected for real world usage in the SuperPicky app.

### Run Code
##### Run Training
- main.py allows specifying the training of 1 model and uses the train.py template to train
- to run a grid search use grid_search.py this will go through the training process for all model and configuration options (as specified and generated through config.py)

##### Evaluation
- To evaluate a single model use evaluate.py
- To evaluate the results of the grid search use evaluate_grid.py

##### Model Usage
Refer to predict_samples() in visualization.py for example of model inference. This portion of the code is responsible for testing all models on one sample images and generate the output onto the image, results can be seen in ./results with sample_*****.jpg files.
Images of birds should use Yolo to crop to size before using this model for inference for best performance. 

### Appendix
##### Disclaimer
This report was written entirely without use of AI.

Code was mostly generated by Claude with human review and adjustment where required (including CONFIG_TRACK.md). 

This model was created for SuperPicky, a photo selection application for mac and windows created and distributed by James Yu @jamesphotography in collaboration with Jordan Yu @triple333sR9.